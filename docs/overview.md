# Обзор проекта

Этот документ даёт краткое понимание архитектуры и ключевых сущностей.

## Основной поток
1) Бот добавляется в группу.
2) Сообщения пользователя маршрутизируются на роль.
3) У роли выбрана LLM‑модель (фактически это провайдер + модель).
4) Бот создает/использует сессию провайдера и отправляет сообщение.
5) Ответ возвращается в группу.

## Основные сущности
- **Group** — телеграм‑группа.
- **Role** — роль бота (настройки подсказок, модели, инструкции).
- **GroupRole** — связка роли и группы (override промпта, модель и т.п.).
- **Provider** — описание API LLM в `llm_providers/*.json`.
- **Session** — сессия LLM, привязанная к роли и группе.
- **User fields** — значения, которые бот запрашивает у пользователя (например token, working_dir).

## Где хранится состояние
Хранилище — SQLite (файл в `config.json`):
- роли, группы, настройки ролей;
- сессии;
- история сообщений;
- user_fields (значения, введённые пользователем).

## Форматирование ответов
В `config.json` есть параметры:
- `formatting.mode` — `html` или `markdown` (по умолчанию `markdown`).
- `formatting.allow_raw_html` — разрешает отправку «сырого» HTML от LLM (актуально для режима `html`).

Если включён raw‑режим, бот сначала пытается отправить текст как HTML, а при ошибке Telegram API автоматически делает fallback на экранированный текст.
